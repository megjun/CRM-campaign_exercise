{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "069f89d2-fdcb-4277-a51f-512822bbbe87",
   "metadata": {},
   "source": [
    "# Exercise: CRM campaign_Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995cddde-77ce-4012-9312-e12e0eb372b4",
   "metadata": {},
   "source": [
    "In this notebook we will test our system on the data generated in the notebook `Generate_Data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e8aa10-ab0d-4880-9bfe-51487629f150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory-profiler in /Users/meganejunqueira/opt/anaconda3/lib/python3.9/site-packages (0.61.0)\n",
      "Requirement already satisfied: psutil in /Users/meganejunqueira/opt/anaconda3/lib/python3.9/site-packages (from memory-profiler) (5.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install memory-profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe24a91-4cd5-4001-a681-9b207fc55b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfbd01a-a735-4511-b27a-c1f56b147a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the daily log file and return a DataFrame with the data\n",
    "\n",
    "def read_daily_log_file(log_file):\n",
    "    # Read the daily log file and return a DataFrame containing the data\n",
    "    df = pd.read_csv(log_file, sep='|', header=None, names=['sng_id', 'user_id', 'country'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc273fc-9550-4de0-966a-c05b3257f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute top_songs:\n",
    "\n",
    "def compute_top_songs(data, output_file):\n",
    "   \n",
    "    # Group by 'country' and 'sng_id' and count the streams\n",
    "    # We are using `size()`, because we want to include missing values whether they exist\n",
    "    grouped = data.groupby(['country', 'sng_id']).size().reset_index(name='streams')\n",
    "   \n",
    "    # Sort the data (top songs per country)\n",
    "    sorted_grouped = grouped.sort_values(['country', 'streams'], ascending=[True, False])\n",
    "\n",
    "    # Create a dictionary to store the top_50 songs for each country\n",
    "    top_50_songs = {}\n",
    "    for country, group in sorted_grouped.groupby('country'):\n",
    "        top_50_songs[country] = group.head(50)\n",
    "\n",
    "    # Write the top 50 songs for each country to the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        for country, group in top_50_songs.items():\n",
    "            songs_str = ','.join(f\"{sng_id}:{streams}\" for _, sng_id, streams in group.itertuples(index=False))\n",
    "            file.write(f\"{country}|{songs_str}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba8fb21-917a-4028-941f-0101e6b2b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_folder, output_folder, start_date):\n",
    "    # Convert the start_date to a datetime object\n",
    "    start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    date_range = [start_date - timedelta(days=i) for i in range(1, 8)]\n",
    "\n",
    "    data_list = []  # List to store data for the past 7 days\n",
    "\n",
    "    for day in date_range:\n",
    "        log_file = f\"listen-{day.strftime('%Y-%m-%d')}.txt\"\n",
    "        log_file_path = os.path.join(input_folder, log_file)\n",
    "\n",
    "        if os.path.isfile(log_file_path):\n",
    "            data = read_daily_log_file(log_file_path)\n",
    "            data_list.append(data)\n",
    "            print(f\"Processed log file: {log_file}\")\n",
    "        else:\n",
    "            print(f\"Log file not found: {log_file}\")\n",
    "            \n",
    "\n",
    "    if data_list:\n",
    "        # Concatenate data from the past 7 days into a single DataFrame\n",
    "        combined_data = pd.concat(data_list, ignore_index=True)\n",
    "        output_file = os.path.join(output_folder, f\"country_top50_{start_date.strftime('%Y-%m-%d')}.txt\")\n",
    "        compute_top_songs(combined_data, output_file)\n",
    "        print(f\"Top 50 Songs for the past 7 days saved in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce7345a-2683-4c76-8fe2-9b746317ed44",
   "metadata": {},
   "source": [
    "> Note: the code above is different from the one in my final exercise. The one that I have in my final exercise will work with the current date, this one I will manually input the date I want to start, just then we can check if the code works with the data I generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc81ac5-7508-4322-a09e-69c1257c6d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed log file: listen-2021-12-07.txt\n",
      "Processed log file: listen-2021-12-06.txt\n",
      "Processed log file: listen-2021-12-05.txt\n",
      "Processed log file: listen-2021-12-04.txt\n",
      "Processed log file: listen-2021-12-03.txt\n",
      "Processed log file: listen-2021-12-02.txt\n",
      "Processed log file: listen-2021-12-01.txt\n"
     ]
    }
   ],
   "source": [
    "# Let's check the time that takes this system\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"data\"  \n",
    "    output_folder = \"output_top-50-songs\"  \n",
    "    start_date = '2021-12-08'\n",
    "    \n",
    "    main(input_folder, output_folder, start_date)\n",
    "    \n",
    "    # To calculate the memory used my this system\n",
    "    memory_usage_result = memory_usage((main, (input_folder, output_folder, start_date)))\n",
    "    print(f\"Memory usage: {max(memory_usage_result)} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed638fa-372c-497c-a6cc-121dc16bbe63",
   "metadata": {},
   "source": [
    "> **Note**: Before combining all the data from the 7 files in one DataFrame the code was working as expected. However now that we have combined the data from the 7 files into one DataFrame, the code is taking more time to run. The next step would be try to make the code run more faster (the code is running for more than 2 hours now). Before combining all the data into one DataFrame, we were calculating the top 50 songs per country and per day, whihch was more light than the actual DataFrame the code is dealing right now. This is my solution, which should take some time but works, if I would have more time, I would try to make it more fast, find a way to make it run (compute) in a faster way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11f23a-24df-4055-bf37-877bd9869247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
